{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from data.dataset import Observation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_entries = 50000\n",
    "X_MIN = -4\n",
    "X_MAX = 4\n",
    "NUM_DIMS = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prob_func(x: list[float]) -> np.ndarray:\n",
    "    top = abs(np.sum([(abs(X_MIN)+1)*(abs(X_MAX)+1) for dim in x]))\n",
    "    p0 = abs(np.sum([(dim+1)*(dim+1) for dim in x]))/top\n",
    "    p = [p0, 1-p0]\n",
    "    p /= sum(p)\n",
    "    return p\n",
    "\n",
    "def val_func(x: list[float]) -> np.ndarray:\n",
    "    # returns array of y values. each y value is a function f(y_i) = (x_1, ..., x_n)\n",
    "    val = float(np.random.choice([0,1], size=1, p=prob_func(x)))\n",
    "    return val\n",
    "    # val = np.array([(dim+1)*(dim+1) for dim in x])\n",
    "    # return np.mean(val)\n",
    "\n",
    "def prob_2_func(x: list[float]) -> np.ndarray:\n",
    "    top = abs(np.sum([(abs(X_MIN)+1)*(abs(X_MAX)+1) for dim in x]))\n",
    "    p0 = abs(np.sum([(dim-1)*(dim-1) for dim in x]))/top\n",
    "    p = [p0, 1-p0]\n",
    "    p /= sum(p)\n",
    "    return p\n",
    "\n",
    "def val_2_func(x: list[float]) -> np.ndarray:\n",
    "    # returns array of y values. each y value is a function f(y_i) = (x_1, ..., x_n)\n",
    "    val = float(np.random.choice([0,1], size=1, p=prob_2_func(x)))\n",
    "    return val\n",
    "    # val = np.array([(dim+1)*(dim+1) for dim in x])\n",
    "    # return np.mean(val)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NUM_LABELS = 2\n",
    "\n",
    "data_x_1 = np.ndarray(shape=(int(num_entries/2), NUM_DIMS))\n",
    "data_x_2 = np.ndarray(shape=(int(num_entries/2), NUM_DIMS))\n",
    "data_x_1[:,0] = np.around(np.random.normal(-2,0.6,int(num_entries/2)), decimals=1)\n",
    "data_x_1[:,1] = np.around(np.random.normal(-1,0.6,int(num_entries/2)), decimals=1)\n",
    "data_x_1[:,2] = np.around(np.random.triangular(-4,-1,4,int(num_entries/2)), decimals=1)\n",
    "data_x_2[:,0] = np.around(np.random.normal(2, 0.6, int(num_entries/2)), decimals=1)\n",
    "data_x_2[:,1] = np.around(np.random.normal(2, 0.6, int(num_entries/2)), decimals=1)\n",
    "data_x_2[:,2] = np.around(np.random.triangular(-4,3,4,int(num_entries/2)), decimals=1)\n",
    "data_x = np.concatenate((data_x_1, data_x_2), axis=0)\n",
    "data_x = np.where(data_x > X_MAX, np.full(data_x.shape, X_MAX), data_x)\n",
    "data_x = np.where(data_x < X_MIN, np.full(data_x.shape, X_MIN), data_x)\n",
    "data_y = np.ndarray(shape=(num_entries, NUM_LABELS))\n",
    "data_y[:, 0] = [val_func(x) for x in data_x]\n",
    "data_y[:, 1] = [val_2_func(x) for x in data_x]\n",
    "\n",
    "def plot(data_x, data_y, cmap = \"gist_rainbow\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    scat = ax.scatter(x=data_x[:,0], y=data_x[:,1], c=data_y[:, 0], cmap=cmap)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    fig.colorbar(scat, ax=ax, label='z')\n",
    "plot(data_x=data_x, data_y=data_y, cmap=\"bwr\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def aggregate_by(data_y: torch.tensor, meta: list[Observation]):\n",
    "    def get_entries(indices):\n",
    "        return torch.index_select(data_y, 0, torch.tensor(indices))\n",
    "\n",
    "    def aggregate(entries: torch.tensor):\n",
    "        return entries.mean(axis=0)\n",
    "\n",
    "    obs_y = torch.stack([aggregate(get_entries(obs.entries_indices)) for obs in meta]).float()\n",
    "    return obs_y\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_independent_observations(data_y: torch.tensor, num_observations: int) -> list[\n",
    "    torch.tensor, list[Observation]]:\n",
    "    # returned data_y is a tensor shaped (entries, values)\n",
    "    entry_no = len(data_y)\n",
    "    meta = np.linspace(0, entry_no, entry_no, endpoint=False, dtype=int)\n",
    "    np.random.shuffle(meta)\n",
    "    meta = np.array_split(meta, num_observations)\n",
    "    meta = [Observation(x, i) for i, x in enumerate(meta)]\n",
    "\n",
    "    obs_y = aggregate_by(data_y, meta)\n",
    "    return [obs_y, meta]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_dependent_observations(data_x: torch.tensor, data_y: torch.tensor, num_observations: int, dims:list[int]) -> list[torch.tensor, list[Observation]]:\n",
    "    # returned data_y is a tensor shaped (entries, values)\n",
    "    meta = np.linspace(X_MIN, X_MAX, abs(X_MAX - X_MIN) * 10 + 1, endpoint=True, dtype=float)\n",
    "\n",
    "    aggregation_masks = [torch.ones(num_entries, dtype=torch.bool)]\n",
    "    for dim in dims:\n",
    "        new_aggregation_masks = []\n",
    "        for mask in aggregation_masks:\n",
    "            for prev, curr in zip(meta, meta[1:]):\n",
    "                dim_mask = torch.logical_and((data_x[:, dim] <= curr), (data_x[:, dim] >= prev))\n",
    "                aggregation_mask = torch.logical_and(dim_mask, mask)\n",
    "                new_aggregation_masks.append(aggregation_mask)\n",
    "            aggregation_masks = new_aggregation_masks\n",
    "    aggregation_indices = [mask.nonzero(as_tuple=True)[0] for mask in aggregation_masks]\n",
    "    meta = [indices.numpy().tolist() for indices in aggregation_indices if indices.numel() > 0]\n",
    "    # meta = [torch.logical_and((data_x[:, dims] <= curr), (data_x[:, dims] >= prev)).nonzero(as_tuple=True)[0] for prev, curr in\n",
    "    #         zip(meta, meta[1:])]\n",
    "    # meta = [obs.numpy().tolist() for obs in meta if obs.size(dim=0)]\n",
    "    meta = [Observation(x, i) for i, x in enumerate(meta)]\n",
    "\n",
    "    obs_y = aggregate_by(data_y, meta)\n",
    "\n",
    "    return [obs_y, meta]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "def get_data_y(data_x, data_y, dims: list[int], num_observations=10):\n",
    "    data_x = torch.tensor(data_x)\n",
    "    data_y = torch.tensor(data_y)\n",
    "    obs_y, meta = generate_dependent_observations(data_x, data_y, num_observations=num_observations, dims=dims)\n",
    "    for obs in meta:\n",
    "        for index in obs.entries_indices:\n",
    "            data_y[index] = obs_y[obs.value_vec_index]\n",
    "    return data_y.numpy()\n",
    "test_y = np.zeros(np.array(data_y).shape)\n",
    "for dim in range(NUM_DIMS):\n",
    "    test_y += get_data_y(data_x, data_y, [dim])\n",
    "for dim_ab in list(itertools.combinations(range(NUM_DIMS), 2)):\n",
    "    test_y += get_data_y(data_x, data_y, list(dim_ab))\n",
    "plot(data_x=data_x, data_y=test_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "labels = [\"clicks\", \"sales\"]\n",
    "allfeatures = [\"attr_\" + str(i) for i in range(0,NUM_DIMS)]\n",
    "\n",
    "\n",
    "def aggregate_on_features(features, mincount, data):\n",
    "    df = data[labels + features]\n",
    "    df[\"c\"] = 1\n",
    "    df = df.groupby(features).sum().reset_index()\n",
    "    df = df[df.c > mincount].copy()\n",
    "    return df\n",
    "\n",
    "def aggregate_on_all_pairs(\n",
    "    allfeatures,\n",
    "    data,\n",
    "    mincount=0,\n",
    "    gaussian_sigma=None,\n",
    "):\n",
    "    allpairsdf = pd.DataFrame()\n",
    "    for f0 in allfeatures:\n",
    "        feature_1_id = int(f0.split(\"_\")[-1])\n",
    "        for f1 in allfeatures:\n",
    "            feature_2_id = int(f1.split(\"_\")[-1])\n",
    "            if not feature_1_id < feature_2_id:\n",
    "                continue\n",
    "            print(\"aggregating on\", f0, f1)\n",
    "            features = [f0, f1]\n",
    "            df = aggregate_on_features(features, mincount, data)\n",
    "            df[\"feature_1_id\"] = feature_1_id\n",
    "            df[\"feature_2_id\"] = feature_2_id\n",
    "            df = df.rename(\n",
    "                {\n",
    "                    features[0]: \"feature_1_value\",\n",
    "                    features[1]: \"feature_2_value\",\n",
    "                },\n",
    "                axis=1,\n",
    "            )\n",
    "            allpairsdf = pd.concat([allpairsdf, df])\n",
    "    if gaussian_sigma is not None:\n",
    "        allpairsdf[\"c\"] += np.random.normal(0, gaussian_sigma, len(allpairsdf))\n",
    "        allpairsdf[\"click\"] += np.random.normal(0, gaussian_sigma, len(allpairsdf))\n",
    "        allpairsdf[\"sale\"] += np.random.normal(0, gaussian_sigma, len(allpairsdf))\n",
    "    return allpairsdf\n",
    "\n",
    "def aggregate_on_all_single(\n",
    "    allfeatures, data, mincount=0, gaussianSigma=None\n",
    "):\n",
    "    allpairsdf = pd.DataFrame()\n",
    "    for f0 in allfeatures:\n",
    "        print(\"aggregating on\", f0)\n",
    "\n",
    "        features = [f0]\n",
    "        df = aggregate_on_features(features, mincount, data)\n",
    "        df[\"feature_1_id\"] = int(f0.split(\"_\")[-1])\n",
    "        df = df.rename({features[0]: \"feature_1_value\"}, axis=1)\n",
    "        allpairsdf = pd.concat([allpairsdf, df])\n",
    "    if gaussianSigma is not None:\n",
    "        allpairsdf[\"c\"] += np.random.normal(0, gaussianSigma, len(allpairsdf))\n",
    "        allpairsdf[\"click\"] += np.random.normal(0, gaussianSigma, len(allpairsdf))\n",
    "        allpairsdf[\"sale\"] += np.random.normal(0, gaussianSigma, len(allpairsdf))\n",
    "    return allpairsdf\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for i, f in enumerate(allfeatures):\n",
    "    data[f] = np.array(data_x)[:, i]\n",
    "for i, l in enumerate(labels):\n",
    "    data[l] = np.array(data_y).reshape((len(data_y), len(labels)))[:, i]\n",
    "aggregates_single = aggregate_on_all_single(allfeatures, data=data)\n",
    "aggregates_pairs = aggregate_on_all_pairs(allfeatures, data=data, mincount=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aggregates_pairs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from statistics import mean\n",
    "class TestDataGraph(nx.DiGraph):\n",
    "    def __init__(self):\n",
    "        super().__init__(self)\n",
    "\n",
    "    @staticmethod\n",
    "    def probability(individual_count: int, sum_count: float, mean_count: float, no_objects: int):\n",
    "        return (np.float64(individual_count) + np.float64(mean_count)) / (\n",
    "                np.float64(sum_count) + (np.float64(no_objects) * np.float64(mean_count)))\n",
    "\n",
    "    def get_probabilities_for(self, objects, from_objects=None):\n",
    "        if from_objects is None:\n",
    "            from_objects = objects\n",
    "        objects_counts = [float(from_objects[obj][\"count\"]) for obj in objects]\n",
    "        sum_count = sum(objects_counts)\n",
    "        mean_count = mean(objects_counts)\n",
    "        return np.array(\n",
    "            [self.probability(individual_count, sum_count, mean_count, len(objects_counts)) for individual_count in\n",
    "             objects_counts])\n",
    "\n",
    "    def assign_probabilities(self):\n",
    "        to_delete = []\n",
    "        for node in tqdm(self.nodes(), total=self.number_of_nodes(), desc=\"Removing unreachable nodes\"):\n",
    "            node_edges = self.edges(node)\n",
    "            if len(node_edges) == 0:\n",
    "                to_delete.append(node)\n",
    "        for node in to_delete:\n",
    "            self.remove_node(node)\n",
    "        del to_delete\n",
    "\n",
    "        node_probabilities = {}\n",
    "        edge_probabilities = {}\n",
    "        nprobs = self.get_probabilities_for(self.nodes())\n",
    "        for node, prob in tqdm(zip(self.nodes(), nprobs), total=self.number_of_nodes(), desc=\"Assigning probabilities\"):\n",
    "            node_probabilities[node] = prob\n",
    "            edge_probs = self.get_probabilities_for(self.edges(node), self.edges())\n",
    "            for edge, eprob in zip(self.edges(node), edge_probs):\n",
    "                edge_probabilities[edge] = eprob\n",
    "        del nprobs\n",
    "        nx.set_node_attributes(self, node_probabilities, name=\"prob\")\n",
    "        del node_probabilities\n",
    "        nx.set_edge_attributes(self, edge_probabilities, name=\"prob\")\n",
    "        del edge_probabilities\n",
    "\n",
    "    def create_nodes(self, data_singles):\n",
    "        for entry in data_singles:\n",
    "            feature_value, clicks, sales, count, feature_id = entry\n",
    "            node = f\"attr_{int(feature_id)}_val_{feature_value}\"\n",
    "            self.add_node(node, count=float(count), clicks=float(clicks), sales=float(sales))\n",
    "\n",
    "    def create_edges(self, data_pairs):\n",
    "        for entry in data_pairs:\n",
    "            feature_1_value, feature_2_value, clicks, sales, count, feature_1_id, feature_2_id = entry\n",
    "            node_a = f\"attr_{int(feature_1_id)}_val_{feature_1_value}\"\n",
    "            node_b = f\"attr_{int(feature_2_id)}_val_{feature_2_value}\"\n",
    "            self.add_edge(node_a, node_b, count=float(count), clicks=float(clicks), sales=float(sales))\n",
    "            self.add_edge(node_b, node_a, count=float(count), clicks=float(clicks), sales=float(sales))\n",
    "\n",
    "    def prep(self, data_singles, data_pairs):\n",
    "        self.create_nodes(data_singles)\n",
    "        self.create_edges(data_pairs)\n",
    "        self.assign_probabilities()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from data.data_generator import DataGenerator\n",
    "from data.ctr_normalize import CTRNormalize\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_graph = TestDataGraph()\n",
    "data_graph.prep(data_singles=aggregates_single.to_numpy(), data_pairs=aggregates_pairs.to_numpy())\n",
    "DG = DataGenerator(data_graph=data_graph, ctr_normalize=CTRNormalize.no_action, no_attributes=len(allfeatures))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "DG.generate_entry()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_yp = [[prob_func(x)[1], prob_2_func(x)[1]] for x in data_x]\n",
    "gen_data_x = []\n",
    "gen_data_y = []\n",
    "for i in tqdm(range(num_entries)):\n",
    "    x, y = DG.generate_entry()\n",
    "    gen_data_x.append([float(entry) for entry in x])\n",
    "    gen_data_y.append([float(entry) for entry in y])\n",
    "plot(data_x=np.array(gen_data_x), data_y=np.array(gen_data_y))\n",
    "plot(data_x=np.array(data_x), data_y=np.array(data_yp))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "data_gen_dest = os.getcwd() + \"/datasets/criteo/prepared/generated.csv\"\n",
    "DG.generate_data(1000, filename=data_gen_dest, force=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
